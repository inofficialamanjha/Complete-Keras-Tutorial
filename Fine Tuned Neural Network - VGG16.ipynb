{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "imported-shopping",
   "metadata": {},
   "source": [
    "# Build a Fine-Tuned Neural Network\n",
    "\n",
    "The pre-trained model we are gonna use is called VGG16 ( Won the 2014 ImageNet competitions ).\n",
    "\n",
    "Image-Net contains 1000 Images per 1000 Classes.\n",
    "\n",
    "Note : Cats and Dogs were already part of the 1000's classes on ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-nowhere",
   "metadata": {},
   "source": [
    "# Codes Needed from Previous CNN Tut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "consolidated-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dental-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"C:\\Local Disk\\Programming\\Python Projects\\keras complete\\dogs-vs-cats\\Processed\\train\"\n",
    "valid_path = r\"C:\\Local Disk\\Programming\\Python Projects\\keras complete\\dogs-vs-cats\\Processed\\valid\"\n",
    "test_path = r\"C:\\Local Disk\\Programming\\Python Projects\\keras complete\\dogs-vs-cats\\Processed\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acting-adoption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(224,224), classes = ['cat','dog'], batch_size=10)\n",
    "\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    ".flow_from_directory(directory=valid_path, target_size=(224,224), classes = ['cat','dog'], batch_size=10)\n",
    "\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    ".flow_from_directory(directory=test_path, target_size=(224,224), classes = ['cat','dog'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "herbal-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion matrix',cmap = plt.cm.Blues):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting 'normalize=True'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest',cmap=cmap) # defining blue color-maps\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks,classes,rotation=45)\n",
    "    plt.yticks(tick_marks,classes)\n",
    "    \n",
    "    if normalize :\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
    "        print(\"Normalized Confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "        \n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max()/ 2.\n",
    "    \n",
    "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])) :\n",
    "        plt.text(j,i,cm[i,j],\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i,j] > thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-easter",
   "metadata": {},
   "source": [
    "# VGG16 Pre-processing\n",
    "\n",
    "Subtract the mean RGB value, computed on the training set from each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "victorian-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the model\n",
    "\n",
    "vgg16_model = tf.keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tired-prison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comfortable-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our objective is just going to be change the last output layer for 2 outputs\n",
    "\n",
    "def count_params(model):\n",
    "    non_trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in model.non_trainable_weights])\n",
    "    trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in model.trainable_weights])\n",
    "    return {'non_trainable_params' : non_trainable_params, 'trainable_params' : trainable_params}\n",
    "\n",
    "params = count_params(vgg16_model)\n",
    "assert params['non_trainable_params'] == 0\n",
    "assert params['trainable_params'] == 138357544\n",
    "\n",
    "# Just to check that the model has imported correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unlikely-selling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.functional.Functional"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the type of vgg16_model\n",
    "\n",
    "type(vgg16_model) # a model from the Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "advisory-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# covert the vgg16_model into a functional model\n",
    "\n",
    "for layer in vgg16_model.layers[:-1] :\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stylish-classification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # Last layer not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bacterial-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = count_params(model)\n",
    "assert params['non_trainable_params'] == 0\n",
    "assert params['trainable_params'] == 134260544 # if not asset, or if assert fails an 'Assertion Error' is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unexpected-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers :\n",
    "    layer.trainable = False # Freeze the weights and biases in the model for all layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "responsible-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=2, activation='softmax')) # only trainable layer in the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "crazy-marks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # our model now has 8,194 trainable parameters only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-remove",
   "metadata": {},
   "source": [
    "# Training the Fine-Tuned VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "focused-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "honey-subscriber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1800/1800 - 86s - loss: 0.0724 - accuracy: 0.9716 - val_loss: 0.0493 - val_accuracy: 0.9814\n",
      "Epoch 2/10\n",
      "1800/1800 - 88s - loss: 0.0406 - accuracy: 0.9851 - val_loss: 0.0448 - val_accuracy: 0.9826\n",
      "Epoch 3/10\n",
      "1800/1800 - 114s - loss: 0.0321 - accuracy: 0.9883 - val_loss: 0.0472 - val_accuracy: 0.9830\n",
      "Epoch 4/10\n",
      "1800/1800 - 115s - loss: 0.0263 - accuracy: 0.9904 - val_loss: 0.0480 - val_accuracy: 0.9818\n",
      "Epoch 5/10\n",
      "1800/1800 - 136s - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.0464 - val_accuracy: 0.9846\n",
      "Epoch 6/10\n",
      "1800/1800 - 173s - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0474 - val_accuracy: 0.9842\n",
      "Epoch 7/10\n",
      "1800/1800 - 172s - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0510 - val_accuracy: 0.9826\n",
      "Epoch 8/10\n",
      "1800/1800 - 189s - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.0498 - val_accuracy: 0.9842\n",
      "Epoch 9/10\n",
      "1800/1800 - 208s - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.0523 - val_accuracy: 0.9836\n",
      "Epoch 10/10\n",
      "1800/1800 - 265s - loss: 0.0085 - accuracy: 0.9981 - val_loss: 0.0567 - val_accuracy: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x186b4bae0d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches, validation_data=valid_batches,epochs=10,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-shift",
   "metadata": {},
   "source": [
    "# Predict using the Fine-Tuned VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "expressed-configuration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 - 20s\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x=test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alive-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_batches.classes,y_pred=np.argmax(predictions,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "lovely-banana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[985  15]\n",
      " [  7 993]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['cat','dog']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title = \"Confusion matrix\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
